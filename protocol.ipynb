{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CliqueSNV validation protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haplotyping tools and configs:\n",
    "CliqueSNV_fn = \"/home/code/cliquesnv/2.0.2/clique-snv.jar\"\n",
    "aBayesQR_fn = \"/home/code/abayesqr/aBayesQR/aBayesQR\"\n",
    "PredictHaplo_fn = \"/home/code/PredictHaplo-Paired-0.4/PredictHaplo-Paired\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other constants:\n",
    "samtools_dn = \"/home/code/simseq/SimSeq\"\n",
    "picard_dn = \"/home/code/picard/picard-tools-1.119\"\n",
    "\n",
    "base_dn = \"/alina-data0/sergey/CliqueSNV\"\n",
    "\n",
    "HXB2_pol_ref_fn = \"refs/HXB2_pol_ref/ref.fas\"\n",
    "HXB2_fl_ref_fn = \"refs/HXB2_fl/HXB2_fl.fas\"\n",
    "IAV_ref_fn = \"refs/IAV_ref/ref.fa\"\n",
    "HCV_ref_fn = \"refs/HCV_ref/NC_004102_ref.fasta\"\n",
    "ZIKA_ref_fn = \"refs/ZIKA_ref/NC_012532_ref.fasta\"\n",
    "\n",
    "subsample_fn = \"scripts/Subsampler.py\"\n",
    "sim_read_generator_fn = \"scripts/ReadGenerator.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_datasets = [\"HIV9exp\", \"HIV2exp\"]\n",
    "reduced_experimental_datasets = [\"{}_50k_reads\".format(x) for x in experimental_datasets]\n",
    "labmix_dataset = [\"HIV5exp\", \"HIV5exp_fl\"]\n",
    "simulated_datasets = [\"HIV7sim\", \"IAV10sim\", \"HCV10sim\", \"ZIKA3sim\"]\n",
    "fragment_datasets = [\"HIV5exp2k\",\"HIV5exp5k\",\"HCV10sim1k\",\"HCV10sim2k\",\"HCV10sim5k\",\"ZIKA3sim1k\",\"ZIKA3sim2k\",\"ZIKA3sim5k\"]\n",
    "er1 = [\"reads/{}_R1.fastq.gz\".format(x) for x in experimental_datasets]\n",
    "er2 = [\"reads/{}_R2.fastq.gz\".format(x) for x in experimental_datasets]\n",
    "rer1 = [\"reads/{}_R1.fastq.gz\".format(x) for x in reduced_experimental_datasets]\n",
    "rer2 = [\"reads/{}_R2.fastq.gz\".format(x) for x in reduced_experimental_datasets]\n",
    "labmix1 = [\"reads/SRR961514_1.fastq\"]\n",
    "labmix2 = [\"reads/SRR961514_1.fastq\"]\n",
    "sim_hapl = [\"relevant_haplotypes/HIV7sim.fasta\", \"relevant_haplotypes/IAV10sim.fasta\", \"sim_haplotypes/HCV10sim.fasta\", \"sim_haplotypes/ZIKA3sim.fasta\"]\n",
    "rs1 = [\"reads/{}_R1.fastq.gz\".format(x) for x in simulated_datasets]\n",
    "rs2 = [\"reads/{}_R2.fastq.gz\".format(x) for x in simulated_datasets]\n",
    "exp_sams = [\"alignment/{}.sam\".format(x) for x in experimental_datasets]\n",
    "reduced_exp_sams = [\"alignment/{}.sam\".format(x) for x in reduced_experimental_datasets]\n",
    "labmix_sam = [\"alignment/{}.sam\".format(x) for x in labmix_dataset]\n",
    "simulated_sams = [\"alignment/{}.sam\".format(x) for x in simulated_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare simulated HIV7sim, IAV10sim and HCV10sim datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for i in range(len(rs1)):\n",
    "    op = Path(\"reads/tmp\")\n",
    "    op.mkdir(parents=True, exist_ok=True)\n",
    "    od = str(op)\n",
    "    iref = sim_hapl[i]\n",
    "    !python3 $sim_read_generator_fn -c 50000 -s $samtools_dn -p $picard_dn -i $iref -o $od\n",
    "    \n",
    "    i1 = Path(od, \"sim_reads.1.fastq\")\n",
    "    i2 = Path(od, \"sim_reads.2.fastq\")\n",
    "    o1 = rs1[i]\n",
    "    o2 = rs2[i]\n",
    "    \n",
    "    !gzip -c $i1 > $o1\n",
    "    !gzip -c $i2 > $o2\n",
    "    !rm -rf $od"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced HIV9exp and HIV2exp so that the datasets to consist of just 50k reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(er1)):\n",
    "    i1 = er1[i]\n",
    "    i2 = er2[i]\n",
    "    ir1 = rer1[i]\n",
    "    ir2 = rer2[i]\n",
    "    !python3 $subsample_fn --n-samples 50000 --fastq1 $i1 --fastq2 $i2 --fastq1_out $ir1 --fastq2_out $ir2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for r in [HXB2_pol_ref_fn, HXB2_fl_ref_fn, IAV_ref_fn, HCV_ref_fn, ZIKA_ref_fn]:\n",
    "    !bwa index $r\n",
    "all_r1 = er1 + rer1 + labmix1*2 + rs1\n",
    "all_r2 = er2 + rer2 + labmix2*2 + rs2\n",
    "all_sams = exp_sams + reduced_exp_sams + labmix_sam + simulated_sams\n",
    "refs = [HXB2_pol_ref_fn] * 5 + [HXB2_fl_ref_fn, HXB2_pol_ref_fn, IAV_ref_fn, HCV_ref_fn, ZIKA_ref_fn]\n",
    "\n",
    "for i in range(len(all_r1)):\n",
    "    i1 = all_r1[i]\n",
    "    i2 = all_r2[i]\n",
    "    o = all_sams[i]\n",
    "    r = refs[i]\n",
    "    !bwa mem -B 2 $r $i1 $i2 > $o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Protocol of Sensitivity and Specificity analysis for CliqueSNV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running CliqueSNV with different sensitivity thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "datasets = experimental_datasets \\\n",
    "    + reduced_experimental_datasets \\\n",
    "    + labmix_dataset \\\n",
    "    + simulated_datasets \\\n",
    "    + fragment_datasets\n",
    "\n",
    "fragments = {\"HIV5exp2k\":(1672,3671),\n",
    "             \"HIV5exp5k\":(589,5588),\n",
    "             \"HCV10sim1k\":(3800,4799),\n",
    "             \"HCV10sim2k\":(3300,5299),\n",
    "             \"HCV10sim5k\":(1800,6799),\n",
    "             \"ZIKA3sim1k\":(4299,5298),\n",
    "             \"ZIKA3sim2k\":(3799,5798),\n",
    "             \"ZIKA3sim5k\":(2299,7298)}\n",
    "\n",
    "for d in datasets:\n",
    "    for x in [0.1, 0.05, 0.02, 0.01]:\n",
    "        out_dir = str(Path(base_dn, \"results\", \"{}_{}p_CliqueSNV\".format(d, x*100)))\n",
    "        if d in fragments:\n",
    "            b,e = fragments[d]\n",
    "            in_f = str(Path(base_dn, \"alignment\", \"{}.sam\".format(d[:-2])))\n",
    "            !java -Xmx100g -jar $CliqueSNV_fn -m snv-illumina -tf $x -outDir $out_dir -in $in_f -sp $b -ep $e\n",
    "        else:\n",
    "            in_f = str(Path(base_dn, \"alignment\", \"{}.sam\".format(d)))\n",
    "            !java -Xmx100g -jar $CliqueSNV_fn -m snv-illumina -tf $x -outDir $out_dir -in $in_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Protocol of comparison of CliqueSNV with Consensus, PredictHaplo, aBayesQR, and 2SNV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PredictHaplo\n",
    "PredictHaplo failed on HIV7sim and HIV9exp.\n",
    "HIV9exp region reduced from 1:1074 to 1:1065.\n",
    "HIV7sim region reduced from 1:1074 to 25:1050."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "datasets = experimental_datasets \\\n",
    "    + reduced_experimental_datasets \\\n",
    "    + labmix_dataset \\\n",
    "    + simulated_datasets \\\n",
    "    + fragment_datasets\n",
    "\n",
    "for d in datasets:\n",
    "    config_fn = str(Path(base_dn,\"tool_configs/{}_PredictHaplo.config\".format(d)))\n",
    "    out_dir = str(Path(base_dn,\"results/{}_PredictHaplo\".format(d)))\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    os.chdir(out_dir)\n",
    "    !$PredictHaplo_fn $config_fn\n",
    "    os.chdir(base_dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aBayesQR\n",
    "aBayesQR didn't finish on a full HIV2exp and HIV9exp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "datasets = reduced_experimental_datasets \\\n",
    "    + labmix_dataset[0:1] \\\n",
    "    + simulated_datasets[0:2]\n",
    "for d in datasets:\n",
    "    config_fn = str(Path(base_dn,\"tool_configs/{}_aBayesQR.config\".format(d)))\n",
    "    out_dir = str(Path(base_dn,\"results/{}_aBayesQR\".format(d)))\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    os.chdir(out_dir)\n",
    "    !$aBayesQR_fn $config_fn\n",
    "    os.chdir(base_dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "datasets = experimental_datasets \\\n",
    "    + reduced_experimental_datasets \\\n",
    "    + labmix_dataset \\\n",
    "    + simulated_datasets\n",
    "for d in datasets:\n",
    "    out_dir = str(Path(base_dn, \"results/{}_consensus\".format(d)))\n",
    "    in_f = str(Path(base_dn,\"alignment/{}.sam\".format(d)))\n",
    "    !java -jar $CliqueSNV_fn -m consensus-illumina -in $in_f -outDir $out_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create standard fasta for tools' results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {\"HIV9exp\":(0,1065),\n",
    "           \"HIV2exp\":(4,1074),\n",
    "           \"HIV5exp\":(0,1074),\n",
    "           \"HIV5exp_fl\":(0,9276),\n",
    "           \"HIV7sim\":(24,1050),\n",
    "           \"IAV10sim\":(0,2263),\n",
    "           \"HCV10sim\":(0,8992),\n",
    "           \"ZIKA3sim\":(0,9930),\n",
    "           \"HCV10sim2k\":(0,2000),\n",
    "           \"HCV10sim5k\":(0,5000),\n",
    "           \"ZIKA3sim2k\":(0,2000),\n",
    "           \"ZIKA3sim5k\":(0,5000)\n",
    "          }\n",
    "\n",
    "a=list(map(lambda x: [x[0],x[1][0],x[1][1]],regions.items()))\n",
    "b=[[r[col] for r in a] for col in range(len(a[0]))]\n",
    "datasets = pd.DataFrame({\"dataset\":b[0], \"begin_pos\":b[1], \"end_pos\":b[2]})\n",
    "tools = pd.DataFrame({\"tool\":[\"aBayesQR\", \"PredictHaplo\", \"CliqueSNV\", \"consensus\"]})\n",
    "datasets[\"key\"] = 0\n",
    "tools[\"key\"] = 0\n",
    "\n",
    "results = pd.merge(datasets, tools, on=\"key\")\n",
    "results = results.drop(columns=[\"key\"])\n",
    "column_names=[\"dataset\", \"tool\", \"begin_pos\", \"end_pos\"]\n",
    "results = results.reindex(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_results_paths = list()\n",
    "results_paths = list()\n",
    "for i,row in results.iterrows():\n",
    "    n = [row[\"dataset\"]]\n",
    "    if row[\"tool\"] == \"aBayesQR\" and (row[\"dataset\"] == \"HIV9exp\" or\n",
    "                                      row[\"dataset\"] == \"HIV2exp\"):\n",
    "        n.append(\"50k_reads\")\n",
    "    elif row[\"tool\"] == \"CliqueSNV\":\n",
    "        n.append(\"2.0p\")\n",
    "    n.append(row[\"tool\"])\n",
    "    tool_results_paths.append(\"results/\"+\"_\".join(n))\n",
    "    results_paths.append(\"results/\"+\"_\".join([row[\"dataset\"], row[\"tool\"]])+'.fasta')\n",
    "results[\"tool_out_path\"] = tool_results_paths\n",
    "results[\"output_fasta\"] = results_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for converting tools' output to standard form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_fasta_aBayesQR(indir, outf, begin_pos, end_pos):\n",
    "    ins=list()\n",
    "    try:\n",
    "        with open(indir+\"/test_Seq.txt\") as f:\n",
    "            for s in f:\n",
    "                ins.append(s.strip()[begin_pos:end_pos])\n",
    "        with open(indir+\"/test_Freq.txt\") as f:\n",
    "            infr=next(f).strip().split()\n",
    "        seqs=list()\n",
    "        for i,s in enumerate(ins):\n",
    "            sn=\"{}_{}\".format(str(i),infr[i])\n",
    "            seqs.append(SeqRecord(Seq(s),id=sn,description=sn))\n",
    "        SeqIO.write(seqs,outf,\"fasta\")\n",
    "    except:\n",
    "        return\n",
    "\n",
    "def standard_fasta_PredictHaplo(indir, outf, begin_pos, end_pos):\n",
    "    fs=re.findall(\"[^,]*ph_global[^,]*\\.fas\",\",\".join(glob.glob(indir+\"/*\")))\n",
    "    seq_beg_pos=0\n",
    "    seq_end_pos=0\n",
    "    best_range=0\n",
    "    for fn in fs:\n",
    "        a=fn.split(\".\")[0].split(\"_\")\n",
    "        b,e=int(a[-2]),int(a[-1])\n",
    "        if e-b>best_range:\n",
    "            best_range=e-b\n",
    "            seq_beg_pos=b-1\n",
    "            seq_end_pos=e\n",
    "    new_beg_pos = max(0,begin_pos-seq_beg_pos)\n",
    "    new_end_pos = min(seq_end_pos-seq_beg_pos, end_pos-seq_beg_pos)\n",
    "    fn = indir + \"/ph_global_{}_{}.fas\".format(str(seq_beg_pos+1), str(seq_end_pos))\n",
    "    with open(fn) as f:\n",
    "        r=\"\".join(f.read()).replace(\"\\n\",\"\")\n",
    "    hs = list()\n",
    "    seqs=list()\n",
    "    ss = r.split(\">reconstructed_\")\n",
    "    for i in range(1,len(ss)):\n",
    "        hs.append(re.findall(\".*;Freq:(\\d+\\.\\d+).*;EndOfComments([^>]*)\",ss[i])[0])\n",
    "    for i,h in enumerate(hs):\n",
    "        n=\"{}_{}\".format(i,h[0])\n",
    "        seqs.append(SeqRecord(Seq(h[1][new_beg_pos:new_end_pos]),id=n,description=n))\n",
    "    SeqIO.write(seqs,outf,\"fasta\")\n",
    "\n",
    "def standard_fasta_CliqueSNV(indir, outf, begin_pos, end_pos):\n",
    "    fi=glob.glob(indir+\"/*.fasta\")[0]\n",
    "    seqs=list(SeqIO.parse(fi,\"fasta\"))\n",
    "    for s in seqs:\n",
    "        s.seq = Seq(str(s.seq)[begin_pos:end_pos])\n",
    "    SeqIO.write(seqs, outf, \"fasta\")\n",
    "\n",
    "def standard_fasta_consensus(indir, outf, begin_pos, end_pos):\n",
    "    try:\n",
    "        fi=glob.glob(indir+\"/*.fasta\")[0]\n",
    "        seqs=list(SeqIO.parse(fi,\"fasta\"))\n",
    "        seqs[0].id = \"0_fr_1.0\"\n",
    "        seqs[0].seq = Seq(str(seqs[0].seq)[begin_pos:end_pos])\n",
    "        SeqIO.write(seqs, outf, \"fasta\")\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in results.iterrows():\n",
    "    globals()[\"standard_fasta_\"+row[\"tool\"]](row[\"tool_out_path\"], row[\"output_fasta\"], row[\"begin_pos\"], row[\"end_pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating fasta with relevant haplotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in results.dataset.unique():\n",
    "    begin_pos=results[results.dataset==d].begin_pos.min()\n",
    "    end_pos=results[results.dataset==d].end_pos.max()\n",
    "    seqs=list(SeqIO.parse(\"relevant_haplotypes/\"+d+\".fasta\", \"fasta\"))\n",
    "    for s in seqs:\n",
    "        s.seq=s[begin_pos:end_pos].seq\n",
    "    SeqIO.write(seqs, \"relevant_haplotypes/\"+d+\"_trm\"+\".fasta\", 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_haplotypes=list()\n",
    "for i,row in results.iterrows():\n",
    "    n = row[\"dataset\"]\n",
    "    relevant_haplotypes.append(\"relevant_haplotypes/{}_trm.fasta\".format(n))\n",
    "results[\"relevant_haplotypes_fasta\"] = relevant_haplotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = dict()\n",
    "for i,row in results.iterrows():\n",
    "    n = \"_\".join([row[\"dataset\"], row[\"tool\"]])\n",
    "    p = row[\"output_fasta\"]\n",
    "    r = row[\"relevant_haplotypes_fasta\"]\n",
    "    a = !python scripts/analyze_prediction.py $p $r\n",
    "    stat[n] = json.loads(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_keys = [\"EMD\",\"TP\",\"FP\",\"Et->p\",\"Et<-p\"]\n",
    "stat_keys_dict = {\"EMD\":\"EMD\",\"TP\":\"TP\",\"FP\":\"FP\",\"Et->p\":\"APE\",\"Et<-p\":\"ADC\"}\n",
    "results_df = pd.DataFrame(columns=[\"prediction\"] + stat_keys)\n",
    "for i,row in results.iterrows():\n",
    "    stat_row = list()\n",
    "    p = \"_\".join([row[\"dataset\"], row[\"tool\"]])\n",
    "    stat_row.append(p)\n",
    "    for s in stat_keys:\n",
    "        stat_row.append(stat[p][stat_keys_dict[s]])\n",
    "    results_df.loc[i] = stat_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = experimental_datasets \\\n",
    "    + reduced_experimental_datasets \\\n",
    "    + labmix_dataset \\\n",
    "    + simulated_datasets\n",
    "cliquesnv_stat = dict()\n",
    "for d in datasets:\n",
    "    for x in [0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]:\n",
    "        pf = str(Path(base_dn, \"results\", \"{}_{}p_CliqueSNV/{}.fasta\".format(d, x*100, d)))\n",
    "        if not os.path.exists(pf):\n",
    "            continue\n",
    "        rf = \"relevant_haplotypes/{}.fasta\".format(d.split(\"_\")[0])\n",
    "        a = !python scripts/analyze_prediction.py $pf $rf\n",
    "        p = \"_\".join([d, str(x*100)])\n",
    "        cliquesnv_stat[p] = json.loads(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliquesnv_results_df = pd.DataFrame(columns=[\"prediction\"] + stat_keys)\n",
    "i=0\n",
    "for d in datasets:\n",
    "    for x in [0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]:\n",
    "        p = \"_\".join([d, str(x*100)])\n",
    "        if p not in cliquesnv_stat:\n",
    "            continue\n",
    "        stat_row = list()\n",
    "        stat_row.append(p)\n",
    "        a = cliquesnv_stat[p]\n",
    "        for s in stat_keys:\n",
    "            stat_row.append(a[stat_keys_dict[s]])\n",
    "        cliquesnv_results_df.loc[i] = stat_row\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliquesnv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = experimental_datasets \\\n",
    "    + reduced_experimental_datasets \\\n",
    "    + labmix_dataset \\\n",
    "    + simulated_datasets\n",
    "cliquesnv_t_stat = dict()\n",
    "for d in datasets:\n",
    "    for x in [10, 15, 20, 30, 50, 70, 100, 150, 200, 300, 500]:\n",
    "        pf = str(Path(base_dn, \"results\", \"{}_2p_{}t_CliqueSNV/{}.fasta\".format(d, x, d)))\n",
    "        if not os.path.exists(pf):\n",
    "            continue\n",
    "        rf = \"relevant_haplotypes/{}.fasta\".format(d.split(\"_\")[0])\n",
    "        a = !python scripts/analyze_prediction.py $pf $rf\n",
    "        p = \"_\".join([d, str(x)])\n",
    "        cliquesnv_t_stat[p] = json.loads(a[0])\n",
    "\n",
    "cliquesnv_t_results_df = pd.DataFrame(columns=[\"prediction\"] + stat_keys)\n",
    "i=0\n",
    "for d in datasets:\n",
    "    for x in [10, 15, 20, 30, 50, 70, 100, 150, 200, 300, 500]:\n",
    "        p = \"_\".join([d, str(x)])\n",
    "        if p not in cliquesnv_t_stat:\n",
    "            continue\n",
    "        stat_row = list()\n",
    "        stat_row.append(p)\n",
    "        a = cliquesnv_t_stat[p]\n",
    "        for s in stat_keys:\n",
    "            stat_row.append(a[stat_keys_dict[s]])\n",
    "        cliquesnv_t_results_df.loc[i] = stat_row\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', cliquesnv_t_results_df.shape[0]+1)\n",
    "print(cliquesnv_t_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export statistics as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dir = Path(\"prediction_stats\")\n",
    "stat_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export csv for TP and FP plot (figure 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ect_dfs = dict()\n",
    "for s in stat:\n",
    "    d, t = s.split(\"_\")\n",
    "    if t == \"consensus\":\n",
    "        t = \"Consensus\"\n",
    "    if not d in ect_dfs:\n",
    "        ect_dfs[d] = pd.DataFrame(columns=[\"ECT\",\"Method\"])\n",
    "    for e in stat[s][\"ECT\"]:\n",
    "        ect_dfs[d] = ect_dfs[d].append({\"ECT\": e, \"Method\": t}, ignore_index=True)\n",
    "for df in ect_dfs:\n",
    "    ect_dfs[df].to_csv(Path(stat_dir,df+\"_ECT.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_dfs = dict()\n",
    "for s in stat:\n",
    "    d, t = s.split(\"_\")\n",
    "    if t == \"consensus\":\n",
    "        t = \"Consensus\"\n",
    "    if not d in ecp_dfs:\n",
    "        ecp_dfs[d] = pd.DataFrame(columns=[\"ECP\",\"Method\"])\n",
    "    for e in stat[s][\"ECP\"]:\n",
    "        ecp_dfs[d] = ecp_dfs[d].append({\"ECP\": e, \"Method\": t}, ignore_index=True)\n",
    "for df in ecp_dfs:\n",
    "    ecp_dfs[df].to_csv(Path(stat_dir,df+\"_ECP.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export csv for matching distances (figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dist_df = pd.DataFrame(columns=[\"ADC\",\"APE\",\"Method\",\"Dataset\"])\n",
    "for r in results_df.iterrows():\n",
    "    d, t = r[1][\"prediction\"].split(\"_\")\n",
    "    if t == \"consensus\":\n",
    "        t = \"Consensus\"\n",
    "    match_dist_df=match_dist_df.append({\"ADC\":r[1][\"Et<-p\"],\"APE\":r[1][\"Et->p\"],\"Method\":t,\"Dataset\":d}, ignore_index=True)\n",
    "match_dist_df.to_csv(Path(stat_dir,\"match_dist.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export csv for EMD (figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_df = pd.DataFrame(columns=[\"EMD\",\"Method\",\"Dataset\"])\n",
    "for r in results_df.iterrows():\n",
    "    d, t = r[1][\"prediction\"].split(\"_\")\n",
    "    if t == \"consensus\":\n",
    "        t = \"Consensus\"\n",
    "    emd_df=emd_df.append({\"EMD\":r[1][\"EMD\"],\"Method\":t,\"Dataset\":d}, ignore_index=True)\n",
    "emd_df.to_csv(Path(stat_dir,\"emd.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export csv for precision and recall (table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_df=pd.DataFrame(columns=[\"Dataset\", \"Precision\", \"Recall\"])\n",
    "for s in sorted(stat):\n",
    "    precision_recall_df=precision_recall_df.append({\"Dataset\":s,\n",
    "                                                    \"Precision\":stat[s][\"PPV\"],\n",
    "                                                    \"Recall\":stat[s][\"Sensitivity\"]}, ignore_index=True)\n",
    "precision_recall_df.to_csv(Path(stat_dir,\"precision_recall.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional validation for NAR review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tools on different fragment length for HIV-1 labmix dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIV5_full_length_aln_file = \"refs/HIV5_var_length/HIV5_full_length_aln.fas\"\n",
    "HIV5_full_length_ref_file = \"refs/HIV5_var_length/HIV5_full_length_ref.fas\"\n",
    "HIV5_2000_nt_ref_file = \"refs/HIV5_var_length/HIV5_2000_nt_ref.fas\"\n",
    "HIV5_5000_nt_ref_file = \"refs/HIV5_var_length/HIV5_5000_nt_ref.fas\"\n",
    "HIV5_full_length_sam = \"alignment/HIV5_full_length.sam\"\n",
    "HIV5_2000_nt_sam = \"alignment/HIV5_2000_nt.sam\"\n",
    "HIV5_5000_nt_sam = \"alignment/HIV5_5000_nt.sam\"\n",
    "\n",
    "HIV5_frag_2000 = slice(1795,3795)\n",
    "HIV5_frag_5000 = slice(694,5694)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create reference of length of 2000nt, 5000nt, full length (~9000nt) that has all insertions from all 5 haplotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating full length ref with no gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "seqs = list(SeqIO.parse(HIV5_full_length_aln_file, 'fasta'))\n",
    "\n",
    "ref = list()\n",
    "for j in range(len(seqs[0])):\n",
    "    nucls = {'A': 0, 'C': 0, 'G': 0, 'T':0}\n",
    "    for i in range(len(seqs)):\n",
    "        nuc = seqs[i][j]\n",
    "        if nuc == '-':\n",
    "            continue\n",
    "        nucls[nuc]+=1\n",
    "    sa = sorted(nucls.items(), key=lambda item: item[1], reverse=True)\n",
    "    if sa[0][1] == sa[1][1]:\n",
    "        hxb2_nuc = seqs[1][j]\n",
    "        if hxb2_nuc != '-':\n",
    "            ref.append(hxb2_nuc)\n",
    "            continue\n",
    "    ref.append(sa[0][0])\n",
    "\n",
    "ref_fa = [SeqRecord(Seq(\"\".join(ref)),id=\"HIV1_ref_no_gaps\",description=\"HIV1_ref_no_gaps\")]\n",
    "\n",
    "SeqIO.write(ref_fa, HIV5_full_length_ref_file, 'fasta')\n",
    "\n",
    "ref_2000_fa = [SeqRecord(Seq(\"\".join(ref[HIV5_frag_2000])),id=\"HIV1_2000nt_ref_no_gaps\",description=\"HIV1_2000nt_ref_no_gaps\")]\n",
    "SeqIO.write(ref_2000_fa, HIV5_2000_nt_ref_file, 'fasta')\n",
    "\n",
    "ref_5000_fa = [SeqRecord(Seq(\"\".join(ref[HIV5_frag_5000])),id=\"HIV1_5000nt_ref_no_gaps\",description=\"HIV1_5000nt_ref_no_gaps\")]\n",
    "SeqIO.write(ref_5000_fa, HIV5_5000_nt_ref_file, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align reads to full length reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "HIV5_refs = [HIV5_full_length_ref_file, HIV5_2000_nt_ref_file, HIV5_5000_nt_ref_file]\n",
    "HIV5_sams = [HIV5_full_length_sam, HIV5_2000_nt_sam, HIV5_5000_nt_sam]\n",
    "for i in range(len(HIV5_refs)):\n",
    "    r = HIV5_refs[i]\n",
    "    !bwa index $r\n",
    "    i1 = labmix1[0]\n",
    "    i2 = labmix2[0]\n",
    "    s = HIV5_sams[i]\n",
    "    !bwa mem -B 2 $r $i1 $i2 > $s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CliqueSNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for i in [HIV5_2000_nt_sam, HIV5_5000_nt_sam, HIV5_full_length_sam]:\n",
    "    !java -Xmx100g -jar $CliqueSNV_fn -m snv-illumina -outDir tmp -in $i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PredictHaplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "datasets = [\"HIV5_2000_nt\", \"HIV5_5000_nt\", \"HIV5_full_length\"]\n",
    "for d in datasets:\n",
    "    config_fn = str(Path(base_dn,\"tmp/{}_PredictHaplo.config\".format(d)))\n",
    "    out_dir = str(Path(base_dn,\"tmp/{}_PredictHaplo\".format(d)))\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    os.chdir(out_dir)\n",
    "    !$PredictHaplo_fn $config_fn\n",
    "    os.chdir(base_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"HIV5_2000_nt\", \"HIV5_5000_nt\", \"HIV5_full_length\"]\n",
    "pos = {\"HIV5_2000_nt\":(1,9809), \"HIV5_5000_nt\":(1,2000), \"HIV5_full_length\":(1,5000)}\n",
    "for d in datasets:\n",
    "    indir = \"/alina-data0/sergey/CliqueSNV/tmp/{}_PredictHaplo\".format(d)\n",
    "    outf = \"tmp/{}_PH.fasta\".format(d)\n",
    "    begin_pos = pos[d][0]\n",
    "    end_pos = pos[d][1]\n",
    "    standard_fasta_PredictHaplo(indir, outf, begin_pos, end_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for i in [HIV5_2000_nt_sam, HIV5_5000_nt_sam, HIV5_full_length_sam]:\n",
    "    !java -Xmx100g -jar $CliqueSNV_fn -m consensus-illumina -outDir tmp/HIV5_consensus -in $i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
